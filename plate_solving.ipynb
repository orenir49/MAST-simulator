{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulate\n",
    "from PlateSolve3.PlaneWave import platesolve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.stats import scoreatpercentile, percentileofscore\n",
    "from os import walk,path,makedirs,listdir\n",
    "import shutil\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(ra,dec,bgd,seeing,texp,maxmag,resolution,dirname,filename,kerdir=None):\n",
    "    params = {'max_mag':maxmag,\n",
    "          'ra':ra, 'dec': dec,\n",
    "          'op_mode':'Spectra',\n",
    "          't_exp':texp,\n",
    "          'bgd':bgd,\n",
    "          'seeing':seeing,\n",
    "          'temp':-15,\n",
    "          'read_rms':3,\n",
    "          'resolution':resolution,\n",
    "          'kernel_dir':kerdir\n",
    "          }\n",
    "    image = simulate.simulate_image(params)\n",
    "    filepath = path.join('.','images',dirname,filename) + '.fits'\n",
    "    simulate.save_as_fits(image,params,filepath)\n",
    "\n",
    "def create_images_uniformly(N,bgd,seeing,dirname):\n",
    "    icdf = lambda p: np.rad2deg(np.arccos(1 - 2*p))\n",
    "    dec_arr = icdf(np.random.random(N)) - 90\n",
    "    ra_arr = np.random.uniform(0,360,N)\n",
    "    i_arr = np.arange(1,N+1,1)\n",
    "    texp,maxmag,resolution = 1,15,1\n",
    "\n",
    "    for ra,dec,i in tqdm(zip(ra_arr,dec_arr,i_arr),total = len(i_arr)):\n",
    "        make_image(ra,dec,bgd,seeing,texp,maxmag,resolution,dirname,f'{int(i)}')\n",
    "\n",
    "def create_precision_images(N,bgd,seeing,resolution,base_dir = 'prec'):\n",
    "    p = simulate.plate_scale_arcsec_px.value/3600\n",
    "\n",
    "    icdf = lambda p: np.rad2deg(np.arccos(1 - 2*p))\n",
    "    center_dec = icdf(np.random.random(N)) - 90\n",
    "    center_ra = np.random.uniform(0,360,N)\n",
    "    i_arr = np.arange(1,N+1,1)\n",
    "\n",
    "    kerdir = simulate.create_kernels(resolution,seeing * u.arcsec)\n",
    "    texp,maxmag = 1,16\n",
    "\n",
    "    for ra,dec,i in tqdm(zip(center_ra,center_dec,i_arr),total = len(i_arr)):\n",
    "        dirname = path.join(base_dir,f'{int(i)}')\n",
    "        path_check = path.join('.','images',dirname)\n",
    "        if not path.exists(path_check):\n",
    "            makedirs(path_check)\n",
    "            make_image(ra,dec,bgd,seeing,texp,maxmag,resolution,dirname,'cntr',kerdir)\n",
    "\n",
    "            delta_ra = p * np.cos(dec)\n",
    "            delta_dec = p\n",
    "            shift_ra = np.random.uniform(-4,4) * delta_ra\n",
    "            shift_dec = np.random.uniform(-4,4) * delta_dec\n",
    "            ra2 = ra + shift_ra\n",
    "            dec2 = dec + shift_dec\n",
    "            make_image(ra2,dec2,bgd,seeing,texp,maxmag,resolution,dirname,'shift',kerdir)\n",
    "    \n",
    "    shutil.rmtree(kerdir)\n",
    "    \n",
    "def rand_solve(l,h,t_exp):\n",
    "    i = np.random.randint(low = l,high = h)\n",
    "    platesolve.platesolve(f'./images/exp{int(t_exp)}/{i}.fits',simulate.plate_scale_arcsec_px.value)\n",
    "\n",
    "def stats_solve(dirpath,bgd,seeing,resolution):\n",
    "    \n",
    "    filenames = next(walk(dirpath), (None, None, []))[2]  # [] if no file\n",
    "    n = len(filenames)\n",
    "    ra_img = np.zeros(n)\n",
    "    dec_img = np.zeros(n)\n",
    "    arr1 = np.zeros(n)\n",
    "    arr5 = np.zeros(n)\n",
    "    arr10 = np.zeros(n)\n",
    "    for i in tqdm(range(n)):\n",
    "        hdu = fits.open(path.join(dirpath,filenames[i]))\n",
    "        ra_img[i] = hdu[0].header['RA']\n",
    "        dec_img[i] = hdu[0].header['DEC']\n",
    "        hdu.close()\n",
    "        ps = platesolve.platesolve(path.join(dirpath,filenames[i]),simulate.plate_scale_arcsec_px.value)\n",
    "        if len(ps) > 0: ## if image is solved for 1 sec exposure, mark true for 1,5,10 sec.\n",
    "            arr1[i] = 1\n",
    "            arr5[i] = 1\n",
    "            arr10[i] = 1\n",
    "        else: ## if image isn't solved, check first if it's because I queried too few stars (too many should be covered by simulate.py)\n",
    "            texp = 1\n",
    "            make_image(ra_img[i],dec_img[i],bgd,seeing,texp,17,resolution,dirpath.removeprefix('./images/'),filenames[i].removesuffix('.fits'))\n",
    "            ps2 = platesolve.platesolve(path.join(dirpath,filenames[i]),simulate.plate_scale_arcsec_px.value)\n",
    "            if len(ps2) > 0:\n",
    "                arr1[i] = 1\n",
    "                arr5[i] = 1\n",
    "                arr10[i] = 1\n",
    "            else: ## if that failed as well, try to increase exposure time\n",
    "                texp = 5\n",
    "                make_image(ra_img[i],dec_img[i],bgd,seeing,texp,17,resolution,dirpath.removeprefix('./images/'),filenames[i].removesuffix('.fits'))\n",
    "                ps3 = platesolve.platesolve(path.join(dirpath,filenames[i]),simulate.plate_scale_arcsec_px.value)\n",
    "                if len(ps3) > 0:\n",
    "                    arr5[i] = 1\n",
    "                    arr10[i] = 1\n",
    "                else: ## if 5 sec exposure failed, try 10 also\n",
    "                    texp = 10\n",
    "                    make_image(ra_img[i],dec_img[i],bgd,seeing,texp,17,resolution,dirpath.removeprefix('./images/'),filenames[i].removesuffix('.fits'))\n",
    "                    ps4 = platesolve.platesolve(path.join(dirpath,filenames[i]),simulate.plate_scale_arcsec_px.value)\n",
    "                    if len(ps4) > 0:\n",
    "                        arr10[i] = 1\n",
    "    return pd.DataFrame({'ra':ra_img,'dec':dec_img,'1_sec':arr1,'5_sec':arr5,'10_sec':arr10})\n",
    "\n",
    "def precision_solve(dirpath,bgd,seeing,resolution):\n",
    "    ra_vec = []\n",
    "    dec_vec = []\n",
    "    ra_shift_vec = []\n",
    "    ra_corr_vec = []\n",
    "    dec_shift_vec = []\n",
    "    dec_corr_vec = []\n",
    "    dirs = listdir(dirpath)\n",
    "    kerdir = simulate.create_kernels(resolution,seeing * u.arcsec)\n",
    "\n",
    "    with tqdm(total = len(dirs)) as pbar:\n",
    "        for cur_dir in dirs:\n",
    "            cur_path = path.join(dirpath,cur_dir)\n",
    "            filenames = next(walk(cur_path), (None, None, []))[2]  # [] if no file\n",
    "            n = len(filenames)\n",
    "\n",
    "            cur_ra = []\n",
    "            cur_ra_ps = []\n",
    "            cur_dec = []\n",
    "            cur_dec_ps = []\n",
    "            ra0 = 0\n",
    "            ra0_ps = 0\n",
    "            dec0 = 0\n",
    "            dec0_ps = 0\n",
    "            for i in range(n):\n",
    "                hdu = fits.open(path.join(cur_path,filenames[i]))\n",
    "                cur_ra.append(hdu[0].header['RA'])\n",
    "                cur_dec.append(hdu[0].header['DEC'])\n",
    "                hdu.close()\n",
    "\n",
    "                ps = platesolve.platesolve(path.join(cur_path,filenames[i]),simulate.plate_scale_arcsec_px.value)\n",
    "                if len(ps) > 0:\n",
    "                    cur_ra_ps.append(ps['ra_j2000_hours'] * 15)\n",
    "                    cur_dec_ps.append(ps['dec_j2000_degrees'])\n",
    "                else: ## if platesolve fails, take longer exposure and try again\n",
    "                    make_image(cur_ra[-1],cur_dec[-1],bgd,seeing,5,16,resolution,cur_path.removeprefix('./images/'),filenames[i].removesuffix('.fits'),kerdir)\n",
    "                    ps2 = platesolve.platesolve(path.join(cur_path,filenames[i]),simulate.plate_scale_arcsec_px.value)\n",
    "                    if len(ps2) > 0:\n",
    "                        cur_ra_ps.append(ps2['ra_j2000_hours'] * 15)\n",
    "                        cur_dec_ps.append(ps2['dec_j2000_degrees'])\n",
    "                    else: ## if platesolve fails again, append nan\n",
    "                        cur_ra_ps.append(np.nan)\n",
    "                        cur_dec_ps.append(np.nan)\n",
    "                if filenames[i] == 'cntr.fits':\n",
    "                    ra0 = cur_ra[-1]\n",
    "                    dec0 = cur_dec[-1]\n",
    "                    ra0_ps = cur_ra_ps[-1]\n",
    "                    dec0_ps = cur_dec_ps[-1]\n",
    "            ra_vec.append(ra0)\n",
    "            dec_vec.append(dec0)\n",
    "            ra_shift_vec.append(np.array(cur_ra) - ra0)\n",
    "            ra_corr_vec.append(np.array(cur_ra_ps) - ra0_ps)\n",
    "            dec_shift_vec.append(np.array(cur_dec) - dec0)\n",
    "            dec_corr_vec.append(np.array(cur_dec_ps) - dec0_ps)\n",
    "            pbar.update(1)\n",
    "    if(path.exists('./essential_files/kernels_tmp/')):\n",
    "        shutil.rmtree('./essential_files/kernels_tmp/')\n",
    "    return ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec\n",
    "\n",
    "def precision_to_csv(filename,ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec):\n",
    "    ra_col = []\n",
    "    dec_col = []\n",
    "    ra_shift_col = []\n",
    "    dec_shift_col = []\n",
    "    ra_corr_col = []\n",
    "    dec_corr_col = []\n",
    "\n",
    "    for i in range(len(ra_corr_vec)):\n",
    "        ra0 = ra_vec[i]\n",
    "        dec0 = dec_vec[i]\n",
    "        for j in range(len(ra_corr_vec[i])):\n",
    "            ra_col.append(ra0)\n",
    "            dec_col.append(dec0)\n",
    "            ra_shift_col.append(ra_shift_vec[i][j])\n",
    "            dec_shift_col.append(dec_shift_vec[i][j])\n",
    "            ra_corr_col.append(ra_corr_vec[i][j])\n",
    "            dec_corr_col.append(dec_corr_vec[i][j])\n",
    "\n",
    "    df = pd.DataFrame({'ra':ra_col,'dec':dec_col,'ra_shift':ra_shift_col,\n",
    "                    'dec_shift':dec_shift_col,'ra_corr':ra_corr_col,'dec_corr':dec_corr_col})\n",
    "    filepath = path.join('.','ps_results',filename)\n",
    "    df.to_csv(filepath,index=False)\n",
    "\n",
    "def plot_guiding(ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec):\n",
    "    fig,(ax1,ax2) = plt.subplots(1,2,figsize = (10,5),dpi=120)\n",
    "    \n",
    "    x1_vec = dec_shift_vec / (simulate.plate_scale_arcsec_px.value/3600)\n",
    "    y1_vec = dec_corr_vec / (simulate.plate_scale_arcsec_px.value/3600)\n",
    "\n",
    "    for x,y in zip(x1_vec,y1_vec):\n",
    "        ax1.scatter(x[:10],y[:10],marker='x')\n",
    "    ax1.plot(np.unique(x1_vec),np.unique(x1_vec),ls='--',color='k')\n",
    "    ax1.set_yticks(np.arange(-4,4.5,0.5))\n",
    "    ax1.set_xlabel('Actual shift (px)',fontdict={'size':14})\n",
    "    ax1.set_ylabel('Correction (px)',fontdict={'size':14})\n",
    "    ax1.set_title('plate solving for DEC correction')\n",
    "    ax1.grid()\n",
    "    ax1.set_ylim(-4,4)\n",
    "\n",
    "    x2_vec = ra_shift_vec / (simulate.plate_scale_arcsec_px.value/3600)\n",
    "    y2_vec = ra_corr_vec / (simulate.plate_scale_arcsec_px.value/3600)\n",
    "\n",
    "    for x,y in zip(x2_vec,y2_vec):\n",
    "        ax2.scatter(x,y,marker='x')\n",
    "    ax2.plot(np.unique(x2_vec),np.unique(x2_vec),ls='--',color='k')\n",
    "    ax2.set_yticks(np.arange(-4,4.5,0.5))\n",
    "    ax2.set_xlabel('Actual shift (px)',fontdict={'size':14})\n",
    "    ax2.set_ylabel('Correction (px)',fontdict={'size':14})\n",
    "    ax2.set_title('plate solving for RA correction')\n",
    "    ax2.grid()\n",
    "    ax2.set_ylim(-4,4)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def show_image(filepath):\n",
    "    image = fits.open(path.normpath(filepath))\n",
    "    plt.imshow(image[0].data,norm=LogNorm(),cmap='Greys_r',origin='lower')\n",
    "    print(f'RA {image[0].header[\"RA\"]}')\n",
    "    print(f'DEC {image[0].header[\"DEC\"]}')\n",
    "    print(f'seeing {image[0].header[\"seeing\"]}')\n",
    "    print(f'bgd {image[0].header[\"bgdmagg\"]}')\n",
    "    image.close()\n",
    "    \n",
    "def get_error_arrays(dataframe_lst):\n",
    "    err_lst = []\n",
    "    for df in dataframe_lst:\n",
    "        df = df.iloc[1::2]\n",
    "        dec_err_arcsec = (df['dec_corr'] - df['dec_shift']) * 3600\n",
    "        ra_err_arcsec = (df['ra_corr'] - df['ra_shift']) * 3600\n",
    "        err_arr = (dec_err_arcsec**2 + (ra_err_arcsec * np.cos(np.deg2rad(df['dec'])))**2 )**(1/2)\n",
    "        err_lst.append(err_arr)\n",
    "    return err_lst\n",
    "\n",
    "def plot_error_hist(err_lst):\n",
    "    fig,ax = plt.subplots(figsize=(5,5),dpi=120)\n",
    "    ax.set_xlabel('correction error (arcsec)')\n",
    "    err_arr = np.concatenate(err_lst)\n",
    "    ax.hist(err_arr,bins=100,range=(-3,3),histtype='step',color='RoyalBlue',label=f'{len(err_arr)} attempts')\n",
    "    txt_str = '\\n'.join((\n",
    "    f'50% < {scoreatpercentile(np.abs(err_arr),50):1.2f}\" ',\n",
    "    f'90% < {scoreatpercentile(np.abs(err_arr),90):1.2f}\" ',\n",
    "    f'{percentileofscore(np.abs(err_arr),1):1.0f}% < 1.00\"',\n",
    "    f'99% < {scoreatpercentile(np.abs(err_arr),99):1.2f}\" ',))\n",
    "    props = dict(boxstyle='round', facecolor='k', alpha=0.5)\n",
    "    ax.text(0.05, 0.95, txt_str, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_vs_bgd(err_lst,bgd_lst):\n",
    "    fig,ax = plt.subplots(figsize=(5,5),dpi=120)\n",
    "    ax.set_xlabel('background (mag/arcsec^2)')\n",
    "    ax.set_ylabel('correction error (arcsec)')\n",
    "    mag_arr = np.unique(bgd_lst)\n",
    "    arr50 = []\n",
    "    arr90 = []\n",
    "    arr99 = []\n",
    "    for mag in mag_arr:\n",
    "        err_arr = np.concatenate([err for err,bgd in zip(err_lst,bgd_lst) if bgd == mag])\n",
    "        arr50.append(scoreatpercentile(np.abs(err_arr),50))\n",
    "        arr90.append(scoreatpercentile(np.abs(err_arr),90))\n",
    "        arr99.append(scoreatpercentile(np.abs(err_arr),99))\n",
    "    ax.plot(mag_arr,arr50,label='50%',color='RoyalBlue',ls='--',marker='o',markersize=5)\n",
    "    ax.plot(mag_arr,arr90,label='90%',color='Crimson',ls='--',marker='o',markersize=5)\n",
    "    ax.plot(mag_arr,arr99,label='99%',color='Indigo',ls='--',marker='o',markersize=5)\n",
    "    ax.set_xticks(mag_arr)\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "\n",
    "def plot_error_vs_seeing(err_lst,seeing_lst):\n",
    "    fig,ax = plt.subplots(figsize=(5,5),dpi=120)\n",
    "    ax.set_xlabel('seeing (arcsec)')\n",
    "    ax.set_ylabel('correction error (arcsec)')\n",
    "    seeing_arr = np.unique(seeing_lst)\n",
    "    arr50 = []\n",
    "    arr90 = []\n",
    "    arr99 = []\n",
    "    for seeing in seeing_arr:\n",
    "        err_arr = np.concatenate([err for err,fwhm in zip(err_lst,seeing_lst) if fwhm == seeing])\n",
    "        arr50.append(scoreatpercentile(np.abs(err_arr),50))\n",
    "        arr90.append(scoreatpercentile(np.abs(err_arr),90))\n",
    "        arr99.append(scoreatpercentile(np.abs(err_arr),99))\n",
    "    ax.plot(seeing_arr,arr50,label='50%',color='RoyalBlue',ls='--',marker='o',markersize=5)\n",
    "    ax.plot(seeing_arr,arr90,label='90%',color='Crimson',ls='--',marker='o',markersize=5)\n",
    "    ax.plot(seeing_arr,arr99,label='99%',color='Indigo',ls='--',marker='o',markersize=5)\n",
    "    ax.set_xticks(seeing_arr)\n",
    "    ax.grid()\n",
    "    ax.legend(loc='best')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA 188.503899\n",
      "DEC -23.709716\n",
      "seeing 3.0\n",
      "bgd 18.5\n",
      "RA 188.50457696706\n",
      "DEC -23.7097308338179\n"
     ]
    }
   ],
   "source": [
    "## Verify image looks good\n",
    "\n",
    "# ra,dec = 188.503899,-23.709716\n",
    "# bgd = 18.5\n",
    "# seeing = 3* u.arcsec\n",
    "# texp = 60 * u.s\n",
    "# mag = 16\n",
    "# resolution = 1\n",
    "\n",
    "# make_image(ra,dec,bgd,seeing.value,texp.value,mag,resolution,'test','cntr')\n",
    "# show_image('./images/test/cntr.fits')\n",
    "# ps = platesolve.platesolve('./images/test/cntr.fits',simulate.plate_scale_arcsec_px.value)\n",
    "# if len(ps) > 0:\n",
    "#     print(f\"RA {ps['ra_j2000_hours'] * 15}\")\n",
    "#     print(f\"DEC {ps['dec_j2000_degrees']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create images uniformly for timing the plate solver/checking success rate\n",
    "\n",
    "create_images_uniformly(300,20,3,'test/20_3')\n",
    "create_images_uniformly(300,20,2,'test/20_2')\n",
    "create_images_uniformly(300,20,1,'test/20_1')\n",
    "create_images_uniformly(300,19,3,'test/19_3')\n",
    "create_images_uniformly(300,19,2,'test/19_2')\n",
    "create_images_uniformly(300,19,1,'test/19_1')\n",
    "create_images_uniformly(300,18,3,'test/18_3')\n",
    "create_images_uniformly(300,18,2,'test/18_2')\n",
    "create_images_uniformly(300,18,1,'test/18_1')\n",
    "\n",
    "## when plate solving, if fails, take longer exposure and try again\n",
    "## will plot both 1 sec and 5 sec exposure results\n",
    "df1 = stats_solve('./images/test/20_3',20,3,1)\n",
    "df1.to_csv('./ps_results/solve_vs_exp/294/20_3.csv',index=False)\n",
    "\n",
    "df2 = stats_solve('./images/test/20_2',20,2,1)\n",
    "df2.to_csv('./ps_results/solve_vs_exp/294/20_2.csv',index=False)\n",
    "\n",
    "df3 = stats_solve('./images/test/20_1',20,1,1)\n",
    "df3.to_csv('./ps_results/solve_vs_exp/294/20_1.csv',index=False)\n",
    "\n",
    "df4 = stats_solve('./images/test/19_3',19,3,1)\n",
    "df4.to_csv('./ps_results/solve_vs_exp/294/19_3.csv',index=False)\n",
    "\n",
    "df5 = stats_solve('./images/test/19_2',19,2,1)\n",
    "df5.to_csv('./ps_results/solve_vs_exp/294/19_2.csv',index=False)\n",
    "\n",
    "df6 = stats_solve('./images/test/19_1',19,1,1)\n",
    "df6.to_csv('./ps_results/solve_vs_exp/294/19_1.csv',index=False)\n",
    "\n",
    "df7 = stats_solve('./images/test/18_3',18,3,1)\n",
    "df7.to_csv('./ps_results/solve_vs_exp/294/18_3.csv',index=False)\n",
    "\n",
    "df8 = stats_solve('./images/test/18_2',18,2,1)\n",
    "df8.to_csv('./ps_results/solve_vs_exp/294/18_2.csv',index=False)\n",
    "\n",
    "df9 = stats_solve('./images/test/18_1',18,1,1)\n",
    "df9.to_csv('./ps_results/solve_vs_exp/294/18_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create precision images in directory 'prec'\n",
    "\n",
    "# N = 500\n",
    "# bgd = 20.5\n",
    "# seeing = 1\n",
    "# resolution = 5\n",
    "\n",
    "# create_precision_images(N,bgd,seeing,resolution,base_dir='prec_1_20.5')\n",
    "# if(path.exists('./essential_files/kernels_tmp/')):\n",
    "#     shutil.rmtree('./essential_files/kernels_tmp/')\n",
    "\n",
    "# bgd = 18.5\n",
    "# seeing = 2\n",
    "# create_precision_images(N,bgd,seeing,resolution,base_dir='prec_2_18.5')\n",
    "# if(path.exists('./essential_files/kernels_tmp/')):\n",
    "#     shutil.rmtree('./essential_files/kernels_tmp/')\n",
    "\n",
    "# bgd = 19.5\n",
    "# seeing = 3\n",
    "# create_precision_images(N,bgd,seeing,resolution,base_dir='prec_3_19.5')\n",
    "# if(path.exists('./essential_files/kernels_tmp/')):\n",
    "#     shutil.rmtree('./essential_files/kernels_tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [1:14:34<00:00,  8.95s/it]\n",
      "100%|██████████| 500/500 [1:23:39<00:00, 10.04s/it]\n"
     ]
    }
   ],
   "source": [
    "## Solve images, compute guiding corrections and save to csv\n",
    "\n",
    "# ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec = precision_solve('./images/prec_1_20.5',20.5,1,5)\n",
    "# precision_to_csv('1_20.5.csv',ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec)\n",
    "\n",
    "# ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec = precision_solve('./images/prec_2_18.5',18.5,2,5)\n",
    "# precision_to_csv('2_18.5.csv',ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec)\n",
    "\n",
    "# ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec = precision_solve('./images/prec_3_19.5',19.5,3,5)\n",
    "# precision_to_csv('3_19.5.csv',ra_vec, ra_shift_vec, ra_corr_vec, dec_vec, dec_shift_vec, dec_corr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to solve 7 out of 499 images\n",
      "failed to solve 12 out of 500 images\n",
      "failed to solve 15 out of 500 images\n",
      "failed to solve 10 out of 500 images\n",
      "failed to solve 17 out of 500 images\n",
      "failed to solve 18 out of 500 images\n",
      "failed to solve 12 out of 500 images\n",
      "failed to solve 15 out of 500 images\n",
      "failed to solve 12 out of 500 images\n"
     ]
    }
   ],
   "source": [
    "## Read csv, plot statistics of guiding corrections\n",
    "\n",
    "# df1 = pd.read_csv('./ps_results/1_18.5.csv')\n",
    "# df2 = pd.read_csv('./ps_results/2_19.5.csv')\n",
    "# df3 = pd.read_csv('./ps_results/3_20.5.csv')\n",
    "# df4 = pd.read_csv('./ps_results/1_19.5.csv')\n",
    "# df5 = pd.read_csv('./ps_results/2_20.5.csv')\n",
    "# df6 = pd.read_csv('./ps_results/3_18.5.csv')\n",
    "# df7 = pd.read_csv('./ps_results/1_20.5.csv')\n",
    "# df8 = pd.read_csv('./ps_results/2_18.5.csv')\n",
    "# df9 = pd.read_csv('./ps_results/3_19.5.csv')\n",
    "\n",
    "# err_lst = get_error_arrays([df1,df2,df3,df4,df5,df6,df7,df8,df9])\n",
    "\n",
    "# for i,err in enumerate(err_lst):\n",
    "#     fail = np.count_nonzero(np.isnan(err))\n",
    "#     print(f'failed to solve {fail} out of {len(err)} images')\n",
    "#     err_lst[i] = err[~np.isnan(err)]\n",
    "    \n",
    "\n",
    "# plot_error_hist(err_lst)\n",
    "# plot_error_vs_bgd(err_lst,[18.5,19.5,20.5,19.5,20.5,18.5,20.5,18.5,19.5])\n",
    "# plot_error_vs_seeing(err_lst,[1,2,3,1,2,3,1,2,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAST_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
